{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of PCE data\n",
    "##### import and database communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import ntpath\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pymysql\n",
    "%matplotlib inline\n",
    "DBhost=\"localhost\"\n",
    "DBuser=\"root\"\n",
    "DB = \"PCE\"\n",
    "DBpwd = \"root\"\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "def save_df(dataFrame,tableName,exist):\n",
    "    engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\".format(user=DBuser,pw=DBpwd,db=DB))\n",
    "    dbConnection    = engine.connect()\n",
    "    try:\n",
    "        frame           = dataFrame.to_sql(tableName, dbConnection, if_exists=exist);\n",
    "    except ValueError as vx:\n",
    "        print(vx)\n",
    "    except Exception as ex:   \n",
    "        print(ex)\n",
    "    else:\n",
    "        print(\"Table %s created successfully.\"%tableName);   \n",
    "    finally:\n",
    "        dbConnection.close()\n",
    "\n",
    "\n",
    "def queryDatabase(query):\n",
    "    db2 = pymysql.connect(host=DBhost, user=DBuser, db=DB, password=DBpwd)\n",
    "    db2 = pymysql.connect(host=DBhost, user=DBuser, db=DB, password=DBpwd)\n",
    "    cur2 = db2.cursor()\n",
    "    try:\n",
    "        cur2.execute(query)\n",
    "        rows = cur2.fetchall()\n",
    "    except pymysql.Error as e:\n",
    "        try:\n",
    "            print(\"MySQL Error [%d]: %s\" % (e.args[0], e.args[1]))\n",
    "            return None\n",
    "        except IndexError:\n",
    "            print(\"MySQL Error: %s\" % str(e))\n",
    "            return None\n",
    "    except TypeError as e:\n",
    "        print(\"MySQL Error: TypeError: %s\" % str(e))\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(\"MySQL Error: ValueError: %s\" % str(e))\n",
    "        return None\n",
    "    db2.close()\n",
    "    return rows\n",
    "\n",
    "def saveToDatabase(query, values):\n",
    "    db1 = pymysql.connect(host=DBhost, user=DBuser, db=DB, password=DBpwd)\n",
    "    cur1 = db1.cursor()\n",
    "    try:\n",
    "        cur1.executemany(query, values)\n",
    "        db1.commit()\n",
    "    except pymysql.Error as e:\n",
    "        try:\n",
    "            print( \"MySQL Error [%d]: %s\" % (e.args[0], e.args[1]))\n",
    "            return None\n",
    "        except IndexError:\n",
    "            print( \"MySQL Error: %s\" % str(e))\n",
    "            return None\n",
    "    except TypeError as e:\n",
    "        print(\"MySQL Error: TypeError: %s\" % str(e))\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(\"MySQL Error: ValueError: %s\" % str(e))\n",
    "        return None\n",
    "    db1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating database and storing PAS summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'PAS' already exists.\n",
      "Table 'PAS_by_player' already exists.\n"
     ]
    }
   ],
   "source": [
    "# creating database if not exist\n",
    "conn = pymysql.connect(host='localhost',user='root',password='root')\n",
    "conn.cursor().execute('create database IF NOT EXISTS PCE')\n",
    "\n",
    "# creating PAS table like in the raw format\n",
    "df_PAS = pd.read_csv(r'C:\\Users\\david-bierbrauer\\Documents\\LabRotation\\FroeseUnit\\Teams\\PAS.csv')\n",
    "save_df(df_PAS,\"PAS\",\"fail\")\n",
    "#queryDatabase('ALTER TABLE `pas` ADD PRIMARY KEY( `index`)')\n",
    "\n",
    "# create a player specific version of PAS\n",
    "df_PAS['id'] = df_PAS.index\n",
    "df_click = pd.wide_to_long(df_PAS,stubnames=['Col','Click','PAS','ClickTime'],i='id',j='Player',sep='_',suffix='\\w+').sort_values(by=['Player','TeamID','Team','Trial']).reset_index()\n",
    "save_df(df_click,\"PAS_by_player\",\"fail\")\n",
    "#queryDatabase('ALTER TABLE `pas_by_player` ADD PRIMARY KEY( `index`)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading excel files\n",
    "saving raw, saving cleaned data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Belgas_Round 0', 'Belgas_Round 1', 'Belgas_Round 2', 'Belgas_Round 3', 'Belgas_Round 4', 'Belgas_Round 5', 'Belgas_Round 6', 'Belgas_Round 7', 'Belgas_Round 8', 'Belgas_Round 9', 'Belgas_Round 10', 'Belgas_Round 11', 'Belgas_Round 12', 'Belgas_Round 13', 'Belgas_Round 14', 'Chicos_Round 0', 'Chicos_Round 1', 'Chicos_Round 2', 'Chicos_Round 3', 'Chicos_Round 4', 'Chicos_Round 5', 'Chicos_Round 6', 'Chicos_Round 7', 'Chicos_Round 8', 'Chicos_Round 9', 'Chicos_Round 10', 'Chicos_Round 11', 'Chicos_Round 12', 'Chicos_Round 13', 'Chicos_Round 14', 'Chicos_Round 15', 'Chicos_Round 16', 'Chicos_Round 17', 'Chicos_Round 18', 'Chicos_Round 19', 'El App_Round 0', 'El App_Round 1', 'El App_Round 2', 'El App_Round 3', 'El App_Round 4', 'El App_Round 5', 'El App_Round 6', 'El App_Round 7', 'El App_Round 8', 'El App_Round 9', 'El App_Round 10', 'El App_Round 11', 'El App_Round 12', 'El App_Round 13', 'El App_Round 14', 'El App_Round 15', 'El App_Round 16', 'El App_Round 17', 'El App_Round 18', 'El App_Round 19', 'Emy y Ale_Round 0', 'Emy y Ale_Round 1', 'Emy y Ale_Round 2', 'Emy y Ale_Round 3', 'Emy y Ale_Round 4', 'Emy y Ale_Round 5', 'Emy y Ale_Round 6', 'Emy y Ale_Round 7', 'Emy y Ale_Round 8', 'Emy y Ale_Round 9', 'Emy y Ale_Round 10', 'Emy y Ale_Round 11', 'Emy y Ale_Round 12', 'Emy y Ale_Round 13', 'Emy y Ale_Round 14', 'Emy y Ale_Round 15', 'Emy y Ale_Round 16', 'Emy y Ale_Round 17', 'Emy y Ale_Round 18', 'Emy y Ale_Round 19', 'Medicos_Round 0', 'Medicos_Round 1', 'Medicos_Round 2', 'Medicos_Round 3', 'Medicos_Round 4', 'Medicos_Round 5', 'Medicos_Round 6', 'Medicos_Round 7', 'Medicos_Round 8', 'Medicos_Round 9', 'Medicos_Round 10', 'Medicos_Round 11', 'Medicos_Round 12', 'Medicos_Round 13', 'Medicos_Round 14', 'Medicos_Round 15', 'Medicos_Round 16', 'Medicos_Round 17', 'Medicos_Round 18', 'Medicos_Round 19', 'Redes_Round 0', 'Redes_Round 1', 'Redes_Round 2', 'Redes_Round 3', 'Redes_Round 4', 'Redes_Round 5', 'Redes_Round 6', 'Redes_Round 7', 'Redes_Round 8', 'Redes_Round 9', 'Redes_Round 10', 'Redes_Round 11', 'Redes_Round 12', 'Redes_Round 13', 'Redes_Round 14', 'Redes_Round 15', 'Redes_Round 16', 'Redes_Round 17', 'Redes_Round 18', 'Reta jungla_Round 0', 'Reta jungla_Round 1', 'Reta jungla_Round 2', 'Reta jungla_Round 3', 'Reta jungla_Round 4', 'Reta jungla_Round 5', 'Reta jungla_Round 6', 'Reta jungla_Round 7', 'Reta jungla_Round 8', 'Reta jungla_Round 9', 'Reta jungla_Round 10', 'Reta jungla_Round 11', 'Reta jungla_Round 12', 'Reta jungla_Round 13', 'Reta jungla_Round 14', 'Reta jungla_Round 15', 'Reta jungla_Round 16', 'Reta jungla_Round 17', 'Reta jungla_Round 18', 'Reta jungla_Round 19', 'Siniestros_Round 0', 'Siniestros_Round 1', 'Siniestros_Round 2', 'Siniestros_Round 3', 'Siniestros_Round 4', 'Siniestros_Round 5', 'Siniestros_Round 6', 'Siniestros_Round 7', 'Siniestros_Round 8', 'Siniestros_Round 9', 'Siniestros_Round 10', 'Siniestros_Round 11', 'Siniestros_Round 12', 'Siniestros_Round 13', 'Siniestros_Round 14', 'Siniestros_Round 15', 'Siniestros_Round 16', 'Siniestros_Round 17', 'Siniestros_Round 18', 'Siniestros_Round 19', 'Twenty Five_Round 0', 'Twenty Five_Round 1', 'Twenty Five_Round 2', 'Twenty Five_Round 3', 'Twenty Five_Round 4', 'Twenty Five_Round 5', 'Twenty Five_Round 6', 'Twenty Five_Round 7', 'Twenty Five_Round 8', 'Twenty Five_Round 9', 'Twenty Five_Round 10', 'Twenty Five_Round 11', 'Twenty Five_Round 12', 'Twenty Five_Round 13', 'Twenty Five_Round 14', 'Twenty Five_Round 15', 'Twenty Five_Round 16', 'Twenty Five_Round 17', 'Twenty Five_Round 18', 'Twenty Five_Round 19', 'Vibrantes_Round 0', 'Vibrantes_Round 1', 'Vibrantes_Round 2', 'Vibrantes_Round 3', 'Vibrantes_Round 4', 'Vibrantes_Round 5', 'Vibrantes_Round 6', 'Vibrantes_Round 7', 'Vibrantes_Round 8', 'Vibrantes_Round 9', 'Vibrantes_Round 10', 'Vibrantes_Round 11', 'Vibrantes_Round 12', 'Vibrantes_Round 13', 'Vibrantes_Round 14', 'Vibrantes_Round 15', 'Vibrantes_Round 16', 'Vibrantes_Round 17', 'Vibrantes_Round 18', 'Vibrantes_Round 19']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-160-d336cc4dc334>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"A-Tracker X\"][0] = 0\n",
      "<ipython-input-160-d336cc4dc334>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"B-Tracker X\"][0] = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nadd filenames() \\nfor i in range(0,len(df_list)):\\n    df = df_list[i].copy()\\n    df[\\'Team\\']= teams[i]\\n    df[\\'filename\\']=filenames[i]\\n    save_df(df,\"timeseries_raw\",\"append\")'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_file(filename,df_only = False):    \n",
    "    #### extract information in dictionary ####\n",
    "    with open('{}'.format(filename)) as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            rows =list(csvreader)  # keep only first 2 lines\n",
    "            # concatenate strings of first 2 rows and split into stuff before and after the =\n",
    "            inter = (rows[0][0]+rows[1][0]).split(' = ')\n",
    "            # the \"after =\"-information is at the beginning of each string except the first\n",
    "            # we also don't want to split the last string, since it is only an \"after =\"-information\n",
    "            sequals = [entry.split(' ',1)[0] for entry in inter[1:-1]]+[inter[-1]]\n",
    "            # the \"before =\"-info is at the end of each split, we also add the first \"before=\"\n",
    "            prequals = [inter[0]]+[entry.split(' ',1)[1] for entry in inter[1:-1]]\n",
    "            # we make a dictionary out of the information\n",
    "            header_dict = {prequals[i]:sequals[i] for i in range(len(sequals))}\n",
    "    ### get a column list with the names of the columns\n",
    "    column_list = rows[2][:-1]\n",
    "    ### return a numpy array\n",
    "    arr = np.array(rows[3:])\n",
    "    ### return also a pandas dataframe\n",
    "    df = pd.read_csv(str(filename),skiprows=2,usecols=[i for i in range(len(column_list))])\n",
    "    df.columns = column_list\n",
    "    ### polishing some data\n",
    "    df[\"A-Tracker X\"][0] = 0\n",
    "    df[\"B-Tracker X\"][0] = 0\n",
    "    df[\"System Time\"]= (df[\"System Time\"]-df[\"System Time\"][0])/1000\n",
    "    if df_only == True:\n",
    "        return df\n",
    "    else:\n",
    "        return arr, df, header_dict, column_list\n",
    "\n",
    "def load_files():\n",
    "    mypath = r'C:\\Users\\david-bierbrauer\\Documents\\LabRotation\\FroeseUnit\\Teams{}'\n",
    "    import glob\n",
    "    allfiles = glob.glob(mypath.format(\"\\*\\*.csv\"))\n",
    "    filenames = [path_leaf(name,'tail') for name in glob.glob(mypath.format(\"\\*\\*.csv\"))]\n",
    "    teams = [path_leaf(name,'head') for name in glob.glob(mypath.format(\"\\*\\*.csv\"))]\n",
    "    dfteams = pd.DataFrame(teams,columns=['values'])\n",
    "    dfteams = dfteams.groupby([dfteams['values'].ne(dfteams['values'].shift()).cumsum(), 'values']).size().reset_index(level=0, drop=True)\n",
    "    teamslist = [list(range(0, i)) for i in dfteams]\n",
    "    teamslist = [item for sublist in teamslist for item in sublist]\n",
    "    combined = [\"{}_Round {}\".format(team,trial) for team, trial in zip(teams,teamslist)]\n",
    "    print(combined)\n",
    "    df_list = [load_file(r'{}'.format(file),True) for file in allfiles]\n",
    "    return allfiles,filenames,teams, df_list\n",
    "\n",
    "def path_leaf(path, head_or_tail='tail'):\n",
    "    head, tail = ntpath.split(path)\n",
    "    if head_or_tail== 'tail':\n",
    "        return tail\n",
    "    else:\n",
    "        return ntpath.basename(head)\n",
    "\n",
    "# add filenames to the PAS data\n",
    "def add_filenames():\n",
    "    # create a column if not exist, error will arise if exist, but query will just be ignored\n",
    "    queryDatabase(\"ALTER TABLE `pas` ADD COLUMN filename varchar(100) NOT NULL\")\n",
    "    queryDatabase(\"ALTER TABLE `pas_by_player` ADD COLUMN filename varchar(100) NOT NULL\")\n",
    "    # we have to loop since update just works for specific cells\n",
    "    # files 2 is needed for the long version of the table\n",
    "    for i in range(0, len(filenames)):\n",
    "        files = [(filenames[i], i)]\n",
    "        files2 = [(filenames[i], i+len(filenames))]\n",
    "        saveToDatabase(\"\"\"UPDATE`pas` SET `filename`= %s WHERE `index`=%s\"\"\",files)\n",
    "        saveToDatabase(\"\"\"UPDATE`pas_by_player` SET `filename`= %s WHERE `index`=%s\"\"\",files)\n",
    "        saveToDatabase(\"\"\"UPDATE`pas_by_player` SET `filename`= %s WHERE `index`=%s\"\"\",files2)\n",
    "        \n",
    "# load all files in a list of dataframes\n",
    "allfiles,filenames,teams,df_list = load_files()\n",
    "\n",
    "####  only needed once\n",
    "\"\"\"\n",
    "add filenames() \n",
    "for i in range(0,len(df_list)):\n",
    "    df = df_list[i].copy()\n",
    "    df['Team']= teams[i]\n",
    "    df['filename']=filenames[i]\n",
    "    save_df(df,\"timeseries_raw\",\"append\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preporcessing of timeseries\n",
    "raw velocity/2nd derivetive/acceleration\n",
    "\n",
    "binary velocity/acceleration\n",
    "\n",
    "binary haptic feedback\n",
    "\n",
    "adding information about click times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-4e3c9c496c6d>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_hap_type\"][list(df_TE[\"UserA-Static\"].astype(\"bool\"))]= \"Static\"\n",
      "<ipython-input-100-4e3c9c496c6d>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_hap_type\"][list(df_TE[\"UserB-Static\"].astype(\"bool\"))]= \"Static\"\n",
      "<ipython-input-100-4e3c9c496c6d>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_hap_type\"][list(df_TE[\"UserA-Lure\"].astype(\"bool\"))]= \"Shadow\"\n",
      "<ipython-input-100-4e3c9c496c6d>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_hap_type\"][list(df_TE[\"UserB-Lure\"].astype(\"bool\"))]= \"Shadow\"\n",
      "<ipython-input-100-4e3c9c496c6d>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_hap_type\"][list(df_TE[\"Users Touching\"].astype(\"bool\"))]= \"Avatar\"\n",
      "<ipython-input-100-4e3c9c496c6d>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_hap_type\"][list(df_TE[\"Users Touching\"].astype(\"bool\"))]= \"Avatar\"\n",
      "<ipython-input-100-4e3c9c496c6d>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_button\"][0] = 0\n",
      "<ipython-input-100-4e3c9c496c6d>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_button\"][0] = 0\n",
      "<ipython-input-100-4e3c9c496c6d>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_direction\"][df_TE[\"A-Tracker X\"] > 0] = 1\n",
      "<ipython-input-100-4e3c9c496c6d>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_direction\"][df_TE[\"A-Tracker X\"] < 0] = -1\n",
      "<ipython-input-100-4e3c9c496c6d>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_direction\"][df_TE[\"B-Tracker X\"] > 0] = 1\n",
      "<ipython-input-100-4e3c9c496c6d>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_direction\"][df_TE[\"B-Tracker X\"] < 0] = -1\n",
      "<ipython-input-100-4e3c9c496c6d>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_Acceleration\"][0] = 0\n",
      "<ipython-input-100-4e3c9c496c6d>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_Acceleration\"][0] = 0\n",
      "<ipython-input-100-4e3c9c496c6d>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_abs_Acceleration\"][0] = 0\n",
      "<ipython-input-100-4e3c9c496c6d>:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_abs_Acceleration\"][0] = 0\n",
      "<ipython-input-100-4e3c9c496c6d>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_bin_acc\"][df_TE[\"A_Acceleration\"] > 0] = 1\n",
      "<ipython-input-100-4e3c9c496c6d>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"A_bin_acc\"][df_TE[\"A_Acceleration\"] < 0] = -1\n",
      "<ipython-input-100-4e3c9c496c6d>:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_bin_acc\"][df_TE[\"B_Acceleration\"] > 0] = 1\n",
      "<ipython-input-100-4e3c9c496c6d>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_TE[\"B_bin_acc\"][df_TE[\"B_Acceleration\"] < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n",
      "Table timeseries_preprocessed created successfully.\n"
     ]
    }
   ],
   "source": [
    "# play with timesteps \n",
    "ClickTimes_P1 = df_PAS[\"ClickTime_P1\"].values/1000\n",
    "ClickTimes_P2 = df_PAS[\"ClickTime_P2\"].values/1000\n",
    "\n",
    "def df_TE(i):\n",
    "    df_TE = df_list[i].copy()\n",
    "    # binary series of haptic signals, make bool int combo to make it 1 and 0\n",
    "    df_TE[\"A_hap\"] = df_TE[\"A-Haptic 1\"].astype(\"bool\").astype(\"int\") #maybe diff() for only the first\n",
    "    df_TE[\"B_hap\"] = df_TE[\"B-Haptic 1\"].astype(\"bool\").astype(\"int\")\n",
    "    # define what type of haptic feedback is given, using a boolean mask\n",
    "    df_TE[\"A_hap_type\"] = df_TE[\"A_hap\"]\n",
    "    df_TE[\"B_hap_type\"] = df_TE[\"B_hap\"]\n",
    "    df_TE[\"A_hap_type\"][list(df_TE[\"UserA-Static\"].astype(\"bool\"))]= \"Static\"\n",
    "    df_TE[\"B_hap_type\"][list(df_TE[\"UserB-Static\"].astype(\"bool\"))]= \"Static\"\n",
    "    df_TE[\"A_hap_type\"][list(df_TE[\"UserA-Lure\"].astype(\"bool\"))]= \"Shadow\"\n",
    "    df_TE[\"B_hap_type\"][list(df_TE[\"UserB-Lure\"].astype(\"bool\"))]= \"Shadow\"\n",
    "    df_TE[\"A_hap_type\"][list(df_TE[\"Users Touching\"].astype(\"bool\"))]= \"Avatar\"\n",
    "    df_TE[\"B_hap_type\"][list(df_TE[\"Users Touching\"].astype(\"bool\"))]= \"Avatar\"\n",
    "    # apply diff function to only get the first putton press (in raw data all entries after button press are 1)\n",
    "    df_TE[\"A_button\"] = df_TE[\"A-Buttonstate\"].diff().astype(\"bool\").astype(\"int\")\n",
    "    df_TE[\"B_button\"] = df_TE[\"B-Buttonstate\"].diff().astype(\"bool\").astype(\"int\")\n",
    "    # diff function makes the first one true, we want them false to avoid more conditioning\n",
    "    #that might help to kill the true otherwise if we don't want to manually set the first false\n",
    "    #df_TE[\"B-button\"][(df_TE[\"B-button\"]==True) & (df_TE[\"System Time\"]>0)]\n",
    "    df_TE[\"A_button\"][0] = 0\n",
    "    df_TE[\"B_button\"][0] = 0\n",
    "    # direction is the \"binary\" version of velocity, meaning left is -1, right +1 and standing 0\n",
    "    df_TE[\"A_direction\"] = df_TE[\"A-Tracker X\"]\n",
    "    df_TE[\"A_direction\"][df_TE[\"A-Tracker X\"] > 0] = 1\n",
    "    df_TE[\"A_direction\"][df_TE[\"A-Tracker X\"] < 0] = -1\n",
    "    df_TE[\"B_direction\"] = df_TE[\"B-Tracker X\"]\n",
    "    df_TE[\"B_direction\"][df_TE[\"B-Tracker X\"] > 0] = 1\n",
    "    df_TE[\"B_direction\"][df_TE[\"B-Tracker X\"] < 0] = -1\n",
    "    # turn refers to a binary version the direction. the first timestep in a direction is marked\n",
    "    df_TE[\"A_turning\"] = (0.5*(df_TE[\"A_direction\"] + df_TE[\"A_direction\"].diff()).fillna(0)).astype('int')  \n",
    "    df_TE[\"B_turning\"] = (0.5*(df_TE[\"B_direction\"] + df_TE[\"B_direction\"].diff()).fillna(0)).astype('int')\n",
    "    # acceleration with direction (- for left velocities and + for right velocities)\n",
    "    df_TE[\"A_Acceleration\"] = df_TE[\"A-Tracker X\"].diff()\n",
    "    df_TE[\"B_Acceleration\"] = df_TE[\"B-Tracker X\"].diff()\n",
    "    df_TE[\"A_Acceleration\"][0] = 0\n",
    "    df_TE[\"B_Acceleration\"][0] = 0\n",
    "    # acceleration without direction (hence + for faster and - for slow, independent of left or right)\n",
    "    df_TE[\"A_abs_Acceleration\"] = df_TE[\"A-Tracker X\"].abs().diff()\n",
    "    df_TE[\"B_abs_Acceleration\"] = df_TE[\"B-Tracker X\"].abs().diff()\n",
    "    df_TE[\"A_abs_Acceleration\"][0] = 0\n",
    "    df_TE[\"B_abs_Acceleration\"][0] = 0\n",
    "    # binary acceleration \n",
    "    df_TE[\"A_bin_acc\"] = df_TE[\"A_Acceleration\"]\n",
    "    df_TE[\"A_bin_acc\"][df_TE[\"A_Acceleration\"] > 0] = 1\n",
    "    df_TE[\"A_bin_acc\"][df_TE[\"A_Acceleration\"] < 0] = -1\n",
    "    df_TE[\"B_bin_acc\"] = df_TE[\"B_Acceleration\"]\n",
    "    df_TE[\"B_bin_acc\"][df_TE[\"B_Acceleration\"] > 0] = 1\n",
    "    df_TE[\"B_bin_acc\"][df_TE[\"B_Acceleration\"] < 0] = -1\n",
    "    # times relative to click times\n",
    "    df_TE['time_to_click_of_A'] = round(df_TE['System Time'] - ClickTimes_P1[i],3)\n",
    "    df_TE['time_to_click_of_B'] = round(df_TE['System Time'] - ClickTimes_P2[i],3)\n",
    "    df_TE['Team']= teams[i]\n",
    "    df_TE['Filename']=filenames[i]\n",
    "    # rename tracker-X to raw velocity and pick important columns\n",
    "    df_TE.rename(columns={\"A-Tracker X\": \"A_raw_velocity\", \"B-Tracker X\": \"B_raw_velocity\"},inplace=True)\n",
    "    reduced = df_TE[['Step','System Time','time_to_click_of_A','time_to_click_of_B','A-Position','A_raw_velocity',\n",
    "                     'A_direction','A_turning','A_Acceleration','A_abs_Acceleration','A_bin_acc','A_hap','A_hap_type',\n",
    "                     'B-Position','B_raw_velocity','B_direction','B_turning','B_Acceleration','B_abs_Acceleration',\n",
    "                     'B_bin_acc','B_hap','B_hap_type','Team','Filename']].copy()\n",
    "    return reduced\n",
    "\n",
    "\n",
    "df_preprocessed_list = [df_TE(i) for i in range(len(df_list))]\n",
    "\n",
    "for df in df_preprocessed_list:\n",
    "    save_df(df,\"timeseries_preprocessed\",\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of the files with actual clicks and store them in lists for each player\n",
    "clicks_index_P1 = df_PAS.index[df_PAS[\"ClickTime_P1\"]>=1].tolist()\n",
    "clicks_index_P2 = df_PAS.index[df_PAS[\"ClickTime_P2\"]>=1].tolist()\n",
    "\n",
    "# extract the velocity columns from the dataframes and split up by players\n",
    "P1_raw_velocity_list_byP1 = [df[\"A_raw_velocity\"][(df['time_to_click_of_A']<=0) & (df['time_to_click_of_A']>=-5)] for df in df_preprocessed_list]\n",
    "P2_raw_velocity_list_byP1 = [df[\"B_raw_velocity\"][(df['time_to_click_of_A']<=0) & (df['time_to_click_of_A']>=-5)] for df in df_preprocessed_list]\n",
    "\n",
    "P1_raw_velocity_list_byP2 = [df[\"A_raw_velocity\"][(df['time_to_click_of_B']<=0) & (df['time_to_click_of_B']>=-5)] for df in df_preprocessed_list]\n",
    "P2_raw_velocity_list_byP2 = [df[\"B_raw_velocity\"][(df['time_to_click_of_B']<=0) & (df['time_to_click_of_B']>=-5)] for df in df_preprocessed_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: A_raw_velocity, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "df= df_preprocessed_list[0]\n",
    "print(df[\"A_raw_velocity\"][(df['time_to_click_of_B']<0.0) & (df['time_to_click_of_B']>-5.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
